# [Methods and Statistics in Social Sciences Specialization](https://www.coursera.org/specializations/social-science)

# [Quantitative Methods](https://www.coursera.org/learn/quantitative-methods)

## Learning goals
The goal of this course is to equip you with basic knowledge of the principles of the scientific method and the most important methodological concepts in the social and behavioral sciences. With this knowledge and hands on practice, you will be able to evaluate research articles in terms of their methodological quality. The course will give you insight into the current controversy surrounding the integrity of research in the social and behavioral sciences.This course will also prepare you for subsequent courses on descriptive and inferential statistics and a capstone project where you will apply all this methodological and statistical knowledge and skills by performing your own research project.

You will gain knowledge about:

* the origin of the scientific method and the most important views on philosophy of science
* the scientific method, its principles and criteria for evaluation
* the most important types of research and research designs
* measurement, its methods and criteria for evaluation
* sampling and sampling techniques
* ethics and integrity in science

You will gain experience in:

* evaluating research articles in terms of their methodological quality.


## Week 1

### What makes knowledge scientific?


Non-Scientific methods
1. Intuition/belief
2. Consensus
3. Authority
4. Casual observation
5. Informal logic

**Opinion <> Evidence**

Scientific methods
1. Systematic observation
2. Formal logic, consistently applied

### Principles of Scientific Methods
1. empirically testable
2. replicable: anyone must be able to replicate the study
3. objective: clear assumptions, concepts, procedures
4. transparent: replicated by anyone, publicly shared
5. falsifiable: there must be facts that contradict the hypothesis
6. logically consistent: no internal contradiction

### Claims
* observation: doesn't describe/explain general relation
* hypothesis: describes/explains pattern, general relation
* Law: strongly supported hypothesis
* Theory: overarching explanation of many related phenomena

## Week 2

### Empirical cycle 
* Observation
  * sparks idea for hypothesis
  * pattern, unexpected event, interesting relation we want to explain
  * source not important: personal, shared, imagined, etc.
* Induction
  * with inductive reasoning relation in specific instances is transformed into general rule
* Deduction
  * relation should hold in new instances
  * expectation/prediction is deduced about new observations
  * define concepts, measurement instruments, procedures, sample
  * hypothesis is transformed with deductive reasoning and specificatin of research setup
* Testing
  * data collection
  * compare data to prediction
  * statistical processing
	  * descriptive: summarize
	  * inferential: decide
  * new data collected and - with aid of statistics - compared to predictions
* Evaluation
  * predition cofirmed => hypothesis provisionally supported (**NOT PROVEN!**)
  * prediction disconfirmed => hypothessi not automatically rejected
	* repeat with better research setup
	* ajust hypothesis: by adding additional clauses (modified hypothesis less general)
	* reject hypothesis
  * results are interpreted in terms of the hypothesis (supported/adjusted/rejected)


### What will it take for you to accept a hypothesis?
The empirical cycle describes how we transform an observation into a hypothesis, that is in turn, transformed into a prediction by specifying a research setup. So far, so good. But what does it mean if our prediction is confirmed? What if it's disconfirmed? What does this mean for our hypothesis: Do we accept it or do we reject it?



### What do you look for in a good research study?
If our predictions are confirmed we can't automatically conclude our hypothesis is supported. Alternatively, if our predictions are refuted, we don't necessarily reject our hypothesis. So how do we decide whether our results provide strong or weak support for our hypothesis?


### Criteria for evaluation

* Reliability
  * Replicability: repetition possible
* Validity
  * hypothesized relation
  * accurately reflects reality
  
#### Construct Validity
1. constructs measured/manipulated accurately
2. instruments measure/manupulate intended properties

#### Internal validity
1. hypothesized causal relation
2. observed effect due to hypothesized cause
3. threatened by: plausible alternative explanations

#### External validity
1. hypothesized relation holds in general (other groups & settings)
2. results generalize to other people, groups, environments, times

### How do you identify what caused an effect?
Causality is a very important concept in relation to internal validity. So before we consider internal validity in more detail, we'll first have a look at causality. When do we consider a relation to be causal? What is required?

### Causality
1. Cause and effect are connected: there has to be a way to trace the effect back to the cause
2. Cause precedes effect
3. Cause and effect covary consistently
4. No alternative explanations

** Correlation does not imply causation!**

### What makes a causal explanation less likely?
Internal validity is an important evaluation criterion. If internal validity is low, then support for a hypothesis is weak. To assess a study's internal validity it helps to be aware of different types of threats to internal validity.


### Threats to internal validity
#### Participants
1. maturation: alternative explanation formed by natural change
  * solution: control group
2. selection: alternative explanation due to systematic difference in subject characteristics between groups, other than the manipulated cause
  * solution: random assignment
3. selection by maturation: alternative explanation due to systematic differences in rate of maturation
  * solution: random assignment
  
#### Instruments
1. low construct validity: systematic bias/measures another construct
2. instrumentation: instruments changed during the study
3. testing (sensitization): mesurement affects behavior/provides alternative explanation

#### Artificiality
1. experimenter expectancy: researcher changes behavior (unconsiously) => influences participant's responses
  * solution: experimenter blind design
2. demand characteristics: participant changes behabior (unconsciously)
  * solution: double blind research design/cover story

#### Research setup
1. ambiguous temporal precedence: unclear which comes first cause or effect
  * solution: manipulation of cause (not always possible)
2. history: unforeseen event during study, provides alternative explanation (large/small-scale)
3. mortality: different dropout rates between groups
  * solution: document reasons for dropout
  
### What different relations and roles can variables have?
Before we can move on to the next module and discuss research designs, you first have to know what variables are and what role different types of variables play. In the last two videos we will consider variables that are central to our hypothesis and other, extraneous variables that are not of primary interest, but that might have an unwanted influence. Obvious types are variables that represent the cause and effect, but can you think of other types?

### Variables of Interest

* construct: denotes property in general, abstract terms
* variable: operationalized concrete, expression of construct
  * dependent: effect variable (response/outcome/output)
  * independt: cause variable (input/predictor)
  
### Variables of disinterest
* confounders
  * related to independent + dependent variables
  * partially or entirely accounts for relationship
* control variables
  * likely to be related to independent + dependent variables
  * effects can be controlled for (unlike confounders)
* background variables
  * not relevant in relation between independnt + dependent variables
  * relevant for determining representativeness (age, gender, etc.)
