# [Methods and Statistics in Social Sciences Specialization](https://www.coursera.org/specializations/social-science)

# [Quantitative Methods](https://www.coursera.org/learn/quantitative-methods)

## Learning goals
The goal of this course is to equip you with basic knowledge of the principles of the scientific method and the most important methodological concepts in the social and behavioral sciences. With this knowledge and hands on practice, you will be able to evaluate research articles in terms of their methodological quality. The course will give you insight into the current controversy surrounding the integrity of research in the social and behavioral sciences.This course will also prepare you for subsequent courses on descriptive and inferential statistics and a capstone project where you will apply all this methodological and statistical knowledge and skills by performing your own research project.

You will gain knowledge about:

* the origin of the scientific method and the most important views on philosophy of science
* the scientific method, its principles and criteria for evaluation
* the most important types of research and research designs
* measurement, its methods and criteria for evaluation
* sampling and sampling techniques
* ethics and integrity in science

You will gain experience in:

* evaluating research articles in terms of their methodological quality.


## Week 1

### What makes knowledge scientific?


Non-Scientific methods
1. Intuition/belief
2. Consensus
3. Authority
4. Casual observation
5. Informal logic

**Opinion <> Evidence**

Scientific methods
1. Systematic observation
2. Formal logic, consistently applied

### Principles of Scientific Methods
1. empirically testable
2. replicable: anyone must be able to replicate the study
3. objective: clear assumptions, concepts, procedures
4. transparent: replicated by anyone, publicly shared
5. falsifiable: there must be facts that contradict the hypothesis
6. logically consistent: no internal contradiction

### Claims
* observation: doesn't describe/explain general relation
* hypothesis: describes/explains pattern, general relation
* Law: strongly supported hypothesis
* Theory: overarching explanation of many related phenomena

## Week 2

### Empirical cycle 
* Observation
  * sparks idea for hypothesis
  * pattern, unexpected event, interesting relation we want to explain
  * source not important: personal, shared, imagined, etc.
* Induction
  * with inductive reasoning relation in specific instances is transformed into general rule
* Deduction
  * relation should hold in new instances
  * expectation/prediction is deduced about new observations
  * define concepts, measurement instruments, procedures, sample
  * hypothesis is transformed with deductive reasoning and specificatin of research setup
* Testing
  * data collection
  * compare data to prediction
  * statistical processing
	  * descriptive: summarize
	  * inferential: decide
  * new data collected and - with aid of statistics - compared to predictions
* Evaluation
  * predition cofirmed => hypothesis provisionally supported (**NOT PROVEN!**)
  * prediction disconfirmed => hypothessi not automatically rejected
	* repeat with better research setup
	* ajust hypothesis: by adding additional clauses (modified hypothesis less general)
	* reject hypothesis
  * results are interpreted in terms of the hypothesis (supported/adjusted/rejected)


### What will it take for you to accept a hypothesis?
The empirical cycle describes how we transform an observation into a hypothesis, that is in turn, transformed into a prediction by specifying a research setup. So far, so good. But what does it mean if our prediction is confirmed? What if it's disconfirmed? What does this mean for our hypothesis: Do we accept it or do we reject it?



### What do you look for in a good research study?
If our predictions are confirmed we can't automatically conclude our hypothesis is supported. Alternatively, if our predictions are refuted, we don't necessarily reject our hypothesis. So how do we decide whether our results provide strong or weak support for our hypothesis?


### Criteria for evaluation

* Reliability
  * Replicability: repetition possible
* Validity
  * hypothesized relation
  * accurately reflects reality
  
#### Construct Validity
1. constructs measured/manipulated accurately
2. instruments measure/manupulate intended properties

#### Internal validity
1. hypothesized causal relation
2. observed effect due to hypothesized cause
3. threatened by: plausible alternative explanations

#### External validity
1. hypothesized relation holds in general (other groups & settings)
2. results generalize to other people, groups, environments, times

### How do you identify what caused an effect?
Causality is a very important concept in relation to internal validity. So before we consider internal validity in more detail, we'll first have a look at causality. When do we consider a relation to be causal? What is required?

### Causality
1. Cause and effect are connected: there has to be a way to trace the effect back to the cause
2. Cause precedes effect
3. Cause and effect covary consistently
4. No alternative explanations

** Correlation does not imply causation!**

### What makes a causal explanation less likely?
Internal validity is an important evaluation criterion. If internal validity is low, then support for a hypothesis is weak. To assess a study's internal validity it helps to be aware of different types of threats to internal validity.


### Threats to internal validity
#### Participants
1. maturation: alternative explanation formed by natural change
  * solution: control group
2. selection: alternative explanation due to systematic difference in subject characteristics between groups, other than the manipulated cause
  * solution: random assignment
3. selection by maturation: alternative explanation due to systematic differences in rate of maturation
  * solution: random assignment
  
#### Instruments
1. low construct validity: systematic bias/measures another construct
2. instrumentation: instruments changed during the study
3. testing (sensitization): mesurement affects behavior/provides alternative explanation

#### Artificiality
1. experimenter expectancy: researcher changes behavior (unconsiously) => influences participant's responses
  * solution: experimenter blind design
2. demand characteristics: participant changes behabior (unconsciously)
  * solution: double blind research design/cover story

#### Research setup
1. ambiguous temporal precedence: unclear which comes first cause or effect
  * solution: manipulation of cause (not always possible)
2. history: unforeseen event during study, provides alternative explanation (large/small-scale)
3. mortality: different dropout rates between groups
  * solution: document reasons for dropout
  
### What different relations and roles can variables have?
Before we can move on to the next module and discuss research designs, you first have to know what variables are and what role different types of variables play. In the last two videos we will consider variables that are central to our hypothesis and other, extraneous variables that are not of primary interest, but that might have an unwanted influence. Obvious types are variables that represent the cause and effect, but can you think of other types?

### Variables of Interest

* construct: denotes property in general, abstract terms
* variable: operationalized concrete, expression of construct
  * dependent: effect variable (response/outcome/output)
  * independt: cause variable (input/predictor)
  
### Variables of disinterest
* confounders
  * related to independent + dependent variables
  * partially or entirely accounts for relationship
* control variables
  * likely to be related to independent + dependent variables
  * effects can be controlled for (unlike confounders)
* background variables
  * not relevant in relation between independnt + dependent variables
  * relevant for determining representativeness (age, gender, etc.)
  
 ### Quiz question
 Supose an experiment where we want to answer this question: Would credt card users pay the full amount more often if the card statement is simpler and clearer?
 At the sample selection, we choose to randomsly select men to the treatment group and women to the control group. The results show that the treatment works.
 About the experiment:
 1. Is ok to assume that men tend to pay more often full amount.
 2. There is a selection bias at the sample.
 3. There is a diferent maturation time between the two groups.

##  Week 3
### What are the essential features of a true experiment?
We'll start off with true experiments, that form our best defense against alternative explanations. Before we can look at specific experimental designs, you need to know the general characteristics of an experiment.

#### True Experiments
* maximize internal validity (RCTs)
* manipulation
	* to ensure cause precedes effect
* comparison
	* to ensure effect does not occur naturally
* randomization
	* to ensure there are no other explanations for the effect

### What are other ways of comparing?

Before we get into specific experimental designs, you should be familiar with two key variations on the basic theme (comparing different groups of participants - exposed to different levels of the independent variable - in terms of their score on the dependent variable). First of all, it's possible to look at the separate and combined effect of two or more independent variables in one study. Such research designs are referred to as factorial designs. Second, it is sometimes possible to expose participants to, not one, but all levels of the independent variable. These designs are generally referred to as repeated measured designs.

#### Factorial Designs

* several independent variables (factors) investigated simultaneously.
* main effects: effects on the factors separately
* interaction effects: combined effects
* incomplete designs: not every combination is tested

#### Repeated Measures
* between factor (independent variables that can be manipulated): each participant experiences one level of treatment
* within factor: each participant experiences all levels of treatment

* Repeated Measures Design: measured repeatedly (at least 1 within factor)
* Longitudinal Design: measured repeatedly for a long period

#### Manipulation

* control over independent variable
* value/level determined by researcher
* control over external variables: rule out alternative explanations

* levels/conditions/groups
* fully controlled variable: experimental variable
* intrinsic property of participant that cannot be controlled: individual difference variables
* seemingly non-manipulable variables that can be manipulated

* manipulation check: to be sure manipulation actualy takes place

#### Control of variables of disinterest

* ideal: only difference = independent variable
* Ceteris paribus/all other things equal

* Control Variables

#### Lab vs. Field

* Lab (under researcher control): maximizes *internal validity*
    * low ecological validity:does not imply low construct validity or low external validity
* Field
    * uncontrolled environments
	* maximizes external validity
	
#### Randomization (or random assignment)
* eliminates all systematic differences between participants in different conditions/groups *on average*
* any particular study -> unequal distribution is possible (randomization faillure)
* randomization check: distribution over conditions are equal
* restrited randomization
    * blocking
	* stratified 

##### Randomization with repeated measures
* counterbalancing: order randomized

#### Experimental Designs

* Twu-group design: experimental/control groups, with random assignment

* Twu-group pre/post design: experimental/control groups, with random assignment, with pre-test (to avoid maturation)
    * pre-test can sensitize
	
* Solomon 4-Group design: experiment run twice: one with pre-test, and other without pre-test

* Within/repeated measures: change order of conditions experienced

### What if you cannot assing randomly?
In that case we automatically consider a study quasi-experimental, with a seemingly attractive method to approximate randomisation, called matching.  
Matching can be a really good idea, but in some cases it can be potentially dangerous, because it is a really complex concept.

#### Matching

* threat of selection to internal validity
* pragmatic/ethical reasons
* independent -> individual differences variable (i.e.:sex, age, etc.)

* Matching on relevant background variables
* DANGER: undermatching
    * measured with some error
	* related to the variables of interest
	* due to regression to the mean: when the pool of participants that scored high on first measure, score on average lower on the second one.

#### Quasi-Experimental Designs

* non random assignment
    * impractical/unethical
	* impossible due to individual differences variable = non-manipulable
	* natural events: natural experiments (wars, traumas, etc.)
* sometimes no manipulation, or comparison
* investigates causal relation
* control over extraneous variables
* values selected, not manipulated (like correlational studies)

##### Designs

1. Static group comparison: almost like true experiment except for the non randomized assignment

2. Pre/Post Test Non-equivalent Control Group

3. Interrupted Time-series: more mesurement before and after the experiment intervention (threat of history)

4. Replicated Interrupted Time-series: control-group 

### What if you cannot manipulate either?

Consider correlational designs, where no causal direction is specified or only very modest, cautionary causal inferences are made. There are some special types of research that are important to know, nut that do not fit neatly into the category experimental, quasi-experimental or correlation design.

#### Correlational Designs

* no manipulation of independent variable, or
* no independent variable identified
* no causal direction specified

1. cross section design
2. time-series design: many measurements in time (an individual)
3. panel design: many measurements in time (group of people)

#### Other designs
1. Case study: focus one person/group (as a whole)
    * qualitative: generating hypotheses more than testing
	* negative analysis: contradictary evidence (one counter example)

2. Evaluation research
    * effect of policy/program
	* summarive: outcome/output
	* formative: process
	* applied, usually non-experimental

3. Intervention study
    * effect of treatment on individuals
	* usually quase-experimental
	
4. Validation study
    * assesses quality of instrument

## Week 4

### How do you measure something?

We will start by considering operationalization in more detail. The term operationalization will be distinguished from the more general terms variable and construct.

#### Operationalization

Specific, concrete method to measure/manipulate a construct

Example:
* Abstract, general construct: Political Power. 
* Less abstract, more specific: (variable) influence in parliament.
* Bills passed, years in parliament, analysts to rate 

### What is measurement exactly?

With this bit of terminology (construct/variable/operationalization) out of the way, we can consider what measurement is exactly. This might seem like an easy and obvious question, but measurement is more than just assigning numbers! We will discuss this in the video on the structure of measurement and see that it is assignment of numbers in a way that represents the structure of a certain attribute. The types of structures or relations that we can distinguish are referred to as measurement levels (nominal/ordinal/interval/ratio). This is pretty difficult material, so don't worry if you have to watch these videos several times. It helps to try to come up with your own examples, especially in the video on measurement levels. In the video on variable types we will look at different ways to categorize variables according to their measurement characteristics.

#### Measurement Structure

* what information is (or is not) captured with numbers
* measurement: representatino of relations between persons, groups, objects on a property using relations between numbers

#### Measurement Levels
* type of relationship that can be interpreted
    * inequality: nominal (categorical)
	* order: ordinal (test to assess math ability)
	* differences: interval (temperature)
	* ratios: ratio 

### How do you know whether you have used the right instrument? 
Now that we know what measurement is, how do we determine if an instrument measures the intended property well? In order to assess measurement quality we use the same criteria we used earlier, we will assess measurement quality in terms of validity and reliability. These concepts have a slightly different, more specific meaning in the context of measurement however. The interview with Andries van der Ark also provides some useful information on these concepts! These concepts are discussed with self-report measured in mind, but we do consider observational measures briefly when we look at reliability.

#### Measurement/Construct Validity

* Face validity: expert assessment of the instrument
* Predictive/Criterion validity:
    * instrument predicts relevant property
	* something is measured consistently... not necessarily intended construct
	